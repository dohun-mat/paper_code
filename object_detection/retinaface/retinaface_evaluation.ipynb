{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bbox_overlaps(boxes, query_boxes):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    boxes: (N, 4) ndarray of float\n",
    "    query_boxes: (K, 4) ndarray of float\n",
    "    Returns\n",
    "    -------\n",
    "    overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n",
    "    \"\"\"\n",
    "    N = boxes.shape[0]\n",
    "    K = query_boxes.shape[0]\n",
    "    overlaps = np.zeros((N, K), dtype=np.float64)\n",
    "\n",
    "    for k in range(K):\n",
    "        box_area = (\n",
    "            (query_boxes[k, 2] - query_boxes[k, 0] + 1) *\n",
    "            (query_boxes[k, 3] - query_boxes[k, 1] + 1)\n",
    "        )\n",
    "        for n in range(N):\n",
    "            iw = (\n",
    "                min(boxes[n, 2], query_boxes[k, 2]) -\n",
    "                max(boxes[n, 0], query_boxes[k, 0]) + 1\n",
    "            )\n",
    "            if iw > 0:\n",
    "                ih = (\n",
    "                    min(boxes[n, 3], query_boxes[k, 3]) -\n",
    "                    max(boxes[n, 1], query_boxes[k, 1]) + 1\n",
    "                )\n",
    "                if ih > 0:\n",
    "                    ua = float(\n",
    "                        (boxes[n, 2] - boxes[n, 0] + 1) *\n",
    "                        (boxes[n, 3] - boxes[n, 1] + 1) +\n",
    "                        box_area - iw * ih\n",
    "                    )\n",
    "                    overlaps[n, k] = iw * ih / ua\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Predictions : 100%|████████████████████| 61/61 [00:00<00:00, 69.78it/s]\n",
      "Processing easy: 100%|█████████████████████████| 61/61 [00:37<00:00,  1.63it/s]\n",
      "Processing medium: 100%|███████████████████████| 61/61 [00:36<00:00,  1.69it/s]\n",
      "Processing hard: 100%|█████████████████████████| 61/61 [00:36<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Results ====================\n",
      "Easy   Val AP: 0.9071880291417773\n",
      "Medium Val AP: 0.8813837544774941\n",
      "Hard   Val AP: 0.7339132522904049\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "# from bbox import bbox_overlaps\n",
    "from IPython import embed\n",
    "\n",
    "\n",
    "def get_gt_boxes(gt_dir):\n",
    "    \"\"\" gt dir: (wider_face_val.mat, wider_easy_val.mat, wider_medium_val.mat, wider_hard_val.mat)\"\"\"\n",
    "\n",
    "    gt_mat = loadmat(os.path.join(gt_dir, 'wider_face_val.mat'))\n",
    "    hard_mat = loadmat(os.path.join(gt_dir, 'wider_hard_val.mat'))\n",
    "    medium_mat = loadmat(os.path.join(gt_dir, 'wider_medium_val.mat'))\n",
    "    easy_mat = loadmat(os.path.join(gt_dir, 'wider_easy_val.mat'))\n",
    "\n",
    "    facebox_list = gt_mat['face_bbx_list']\n",
    "    event_list = gt_mat['event_list']\n",
    "    file_list = gt_mat['file_list']\n",
    "\n",
    "    hard_gt_list = hard_mat['gt_list']\n",
    "    medium_gt_list = medium_mat['gt_list']\n",
    "    easy_gt_list = easy_mat['gt_list']\n",
    "\n",
    "    return facebox_list, event_list, file_list, hard_gt_list, medium_gt_list, easy_gt_list\n",
    "\n",
    "\n",
    "def get_gt_boxes_from_txt(gt_path, cache_dir):\n",
    "\n",
    "    cache_file = os.path.join(cache_dir, 'gt_cache.pkl')\n",
    "    if os.path.exists(cache_file):\n",
    "        f = open(cache_file, 'rb')\n",
    "        boxes = pickle.load(f)\n",
    "        f.close()\n",
    "        return boxes\n",
    "\n",
    "    f = open(gt_path, 'r')\n",
    "    state = 0\n",
    "    lines = f.readlines()\n",
    "    lines = list(map(lambda x: x.rstrip('\\r\\n'), lines))\n",
    "    boxes = {}\n",
    "    print(len(lines))\n",
    "    f.close()\n",
    "    current_boxes = []\n",
    "    current_name = None\n",
    "    for line in lines:\n",
    "        if state == 0 and '--' in line:\n",
    "            state = 1\n",
    "            current_name = line\n",
    "            continue\n",
    "        if state == 1:\n",
    "            state = 2\n",
    "            continue\n",
    "\n",
    "        if state == 2 and '--' in line:\n",
    "            state = 1\n",
    "            boxes[current_name] = np.array(current_boxes).astype('float32')\n",
    "            current_name = line\n",
    "            current_boxes = []\n",
    "            continue\n",
    "\n",
    "        if state == 2:\n",
    "            box = [float(x) for x in line.split(' ')[:4]]\n",
    "            current_boxes.append(box)\n",
    "            continue\n",
    "\n",
    "    f = open(cache_file, 'wb')\n",
    "    pickle.dump(boxes, f)\n",
    "    f.close()\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def read_pred_file(filepath):\n",
    "#     print('filepath')\n",
    "#     print(filepath)\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        img_file = lines[0].rstrip('\\n\\r')\n",
    "        lines = lines[2:]\n",
    "#         print(\"!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#         print(lines)\n",
    "        \n",
    "    boxes = np.array(list(map(lambda x: [a for a in x.strip().split()], lines))).astype('float')\n",
    "    return img_file.split('/')[-1], boxes\n",
    "\n",
    "\n",
    "\n",
    "def get_preds(pred_dir):\n",
    "#     print(\"pred_dir\")\n",
    "#     print(pred_dir)\n",
    "    events = os.listdir(pred_dir)\n",
    "#     print('events')\n",
    "#     print(events)\n",
    "    boxes = dict()\n",
    "    pbar = tqdm.tqdm(events)\n",
    "\n",
    "    for event in pbar:\n",
    "        pbar.set_description('Reading Predictions ')\n",
    "        event_dir = os.path.join(pred_dir, event)\n",
    "#         print(\"event_dir\")\n",
    "#         print(event_dir)\n",
    "        event_images = os.listdir(event_dir)\n",
    "#         print(\"event_images\")\n",
    "#         print(event_images)\n",
    "        current_event = dict()\n",
    "        for imgtxt in event_images:\n",
    "            imgname, _boxes = read_pred_file(os.path.join(event_dir, imgtxt))\n",
    "            current_event[imgname.rstrip('.jpg')] = _boxes\n",
    "        boxes[event] = current_event\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def norm_score(pred):\n",
    "    \"\"\" norm score\n",
    "    pred {key: [[x1,y1,x2,y2,s]]}\n",
    "    \"\"\"\n",
    "\n",
    "    max_score = 0\n",
    "    min_score = 1\n",
    "\n",
    "    for _, k in pred.items():\n",
    "        for _, v in k.items():\n",
    "            if len(v) == 0:\n",
    "                continue\n",
    "            _min = np.min(v[:, -1])\n",
    "            _max = np.max(v[:, -1])\n",
    "            max_score = max(_max, max_score)\n",
    "            min_score = min(_min, min_score)\n",
    "\n",
    "    diff = max_score - min_score\n",
    "    for _, k in pred.items():\n",
    "        for _, v in k.items():\n",
    "            if len(v) == 0:\n",
    "                continue\n",
    "            v[:, -1] = (v[:, -1] - min_score)/diff\n",
    "\n",
    "\n",
    "def image_eval(pred, gt, ignore, iou_thresh):\n",
    "    \"\"\" single image evaluation\n",
    "    pred: Nx5\n",
    "    gt: Nx4\n",
    "    ignore:\n",
    "    \"\"\"\n",
    "\n",
    "    _pred = pred.copy()\n",
    "    _gt = gt.copy()\n",
    "    pred_recall = np.zeros(_pred.shape[0])\n",
    "    recall_list = np.zeros(_gt.shape[0])\n",
    "    proposal_list = np.ones(_pred.shape[0])\n",
    "\n",
    "    _pred[:, 2] = _pred[:, 2] + _pred[:, 0]\n",
    "    _pred[:, 3] = _pred[:, 3] + _pred[:, 1]\n",
    "    _gt[:, 2] = _gt[:, 2] + _gt[:, 0]\n",
    "    _gt[:, 3] = _gt[:, 3] + _gt[:, 1]\n",
    "\n",
    "    overlaps = bbox_overlaps(_pred[:, :4], _gt)\n",
    "\n",
    "    for h in range(_pred.shape[0]):\n",
    "\n",
    "        gt_overlap = overlaps[h]\n",
    "        max_overlap, max_idx = gt_overlap.max(), gt_overlap.argmax()\n",
    "        if max_overlap >= iou_thresh:\n",
    "            if ignore[max_idx] == 0:\n",
    "                recall_list[max_idx] = -1\n",
    "                proposal_list[h] = -1\n",
    "            elif recall_list[max_idx] == 0:\n",
    "                recall_list[max_idx] = 1\n",
    "\n",
    "        r_keep_index = np.where(recall_list == 1)[0]\n",
    "        pred_recall[h] = len(r_keep_index)\n",
    "    return pred_recall, proposal_list\n",
    "\n",
    "\n",
    "def img_pr_info(thresh_num, pred_info, proposal_list, pred_recall):\n",
    "    pr_info = np.zeros((thresh_num, 2)).astype('float')\n",
    "    for t in range(thresh_num):\n",
    "\n",
    "        thresh = 1 - (t+1)/thresh_num\n",
    "        r_index = np.where(pred_info[:, 4] >= thresh)[0]\n",
    "        if len(r_index) == 0:\n",
    "            pr_info[t, 0] = 0\n",
    "            pr_info[t, 1] = 0\n",
    "        else:\n",
    "            r_index = r_index[-1]\n",
    "            p_index = np.where(proposal_list[:r_index+1] == 1)[0]\n",
    "            pr_info[t, 0] = len(p_index)\n",
    "            pr_info[t, 1] = pred_recall[r_index]\n",
    "    return pr_info\n",
    "\n",
    "\n",
    "def dataset_pr_info(thresh_num, pr_curve, count_face):\n",
    "    _pr_curve = np.zeros((thresh_num, 2))\n",
    "    for i in range(thresh_num):\n",
    "        _pr_curve[i, 0] = pr_curve[i, 1] / pr_curve[i, 0]\n",
    "        _pr_curve[i, 1] = pr_curve[i, 1] / count_face\n",
    "    return _pr_curve\n",
    "\n",
    "\n",
    "def voc_ap(rec, prec):\n",
    "\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    "\n",
    "\n",
    "def evaluation(pred, gt_path, iou_thresh=0.5):\n",
    "    pred = get_preds(pred)\n",
    "    norm_score(pred)\n",
    "    facebox_list, event_list, file_list, hard_gt_list, medium_gt_list, easy_gt_list = get_gt_boxes(gt_path)\n",
    "    event_num = len(event_list)\n",
    "    thresh_num = 1000\n",
    "    settings = ['easy', 'medium', 'hard']\n",
    "    setting_gts = [easy_gt_list, medium_gt_list, hard_gt_list]\n",
    "    aps = []\n",
    "    for setting_id in range(3):\n",
    "        # different setting\n",
    "        gt_list = setting_gts[setting_id]\n",
    "        count_face = 0\n",
    "        pr_curve = np.zeros((thresh_num, 2)).astype('float')\n",
    "        # [hard, medium, easy]\n",
    "        pbar = tqdm.tqdm(range(event_num))\n",
    "        for i in pbar:\n",
    "            pbar.set_description('Processing {}'.format(settings[setting_id]))\n",
    "            \n",
    "#             print(event_list)\n",
    "#             print(\"~~~~~~~~~~~~~`\")\n",
    "#             print(pred)\n",
    "            \n",
    "            event_name = str(event_list[i][0][0])\n",
    "            img_list = file_list[i][0]\n",
    "            pred_list = pred[event_name]\n",
    "            sub_gt_list = gt_list[i][0]\n",
    "#             \n",
    "#             img_pr_info_list = np.zeros((len(img_list), thresh_num, 2))\n",
    "            gt_bbx_list = facebox_list[i][0]\n",
    "\n",
    "            for j in range(len(img_list)):\n",
    "                pred_info = pred_list[str(img_list[j][0][0])]\n",
    "\n",
    "                gt_boxes = gt_bbx_list[j][0].astype('float')\n",
    "                keep_index = sub_gt_list[j][0]\n",
    "                count_face += len(keep_index)\n",
    "\n",
    "                if len(gt_boxes) == 0 or len(pred_info) == 0:\n",
    "                    continue\n",
    "                ignore = np.zeros(gt_boxes.shape[0])\n",
    "                if len(keep_index) != 0:\n",
    "                    ignore[keep_index-1] = 1\n",
    "                pred_recall, proposal_list = image_eval(pred_info, gt_boxes, ignore, iou_thresh)\n",
    "\n",
    "                _img_pr_info = img_pr_info(thresh_num, pred_info, proposal_list, pred_recall)\n",
    "\n",
    "                pr_curve += _img_pr_info\n",
    "        pr_curve = dataset_pr_info(thresh_num, pr_curve, count_face)\n",
    "\n",
    "        propose = pr_curve[:, 0]\n",
    "        recall = pr_curve[:, 1]\n",
    "\n",
    "        ap = voc_ap(recall, propose)\n",
    "        aps.append(ap)\n",
    "\n",
    "    print(\"==================== Results ====================\")\n",
    "    print(\"Easy   Val AP: {}\".format(aps[0]))\n",
    "    print(\"Medium Val AP: {}\".format(aps[1]))\n",
    "    print(\"Hard   Val AP: {}\".format(aps[2]))\n",
    "    print(\"=================================================\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    import easydict\n",
    "    \n",
    "    args = easydict.EasyDict({\n",
    "        'pred' : '/data/dhk/face/face_detecte/widerface_evaluate/widerface_txt/',\n",
    "        'gt' : './eval_tools/ground_truth'\n",
    "       })\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('-p', '--pred')\n",
    "#     parser.add_argument('-g', '--gt', default='./eval_tools/ground_truth/')\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "    evaluation(args.pred, args.gt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir('/data/dhk/face/face_detecte/widerface_evaluate/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhk",
   "language": "python",
   "name": "dhk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
